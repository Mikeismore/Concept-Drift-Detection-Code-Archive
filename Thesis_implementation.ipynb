{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ef9752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make plot interactive  \n",
    "%matplotlib qt\n",
    "\n",
    "# importing required libraries \n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "from pylab import *\n",
    "import scipy.io\n",
    "import scipy.stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import mat73\n",
    "import random\n",
    "import time\n",
    "\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from ipywidgets import FloatProgress\n",
    "\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6e9095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA(means, m):\n",
    "    '''\n",
    "    means: An array that contains the mean traces of the labels\n",
    "    m: The total points of interest which are compressed\n",
    "    \n",
    "    Returns PCA of the traces\n",
    "    '''\n",
    "    t_mean = np.mean(means, axis=0)\n",
    "    means = means - t_mean\n",
    "    \n",
    "    B = np.dot(means.T, means) / len(means)\n",
    "    U, _, _ = np.linalg.svd(B)\n",
    "    return U[:,0:m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74e0810",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matloader(file_name, newer_mat=False, description=False, file_path=''):\n",
    "    '''\n",
    "    file_name: The name of the file that you're trying to load without the .mat extension.\n",
    "    newer_mat: If the files were saved using a version of matlab that is >= 7.3 use this.\n",
    "    description: If true then it will print a brief description of the loaded file.\n",
    "    file_path: The path where the file is stored\n",
    "    \n",
    "    Returns the loaded matlab data\n",
    "    '''\n",
    "    directory = file_path + file_name + '.mat'\n",
    "    \n",
    "    if description:\n",
    "        print(scipy.io.whosmat(directory))\n",
    "    \n",
    "    if newer_mat:\n",
    "        return mat73.loadmat(directory)\n",
    "    else:\n",
    "        return scipy.io.loadmat(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1901842d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def operation_sorter(labels, dataset, templating=False, reducing=[], size=100):\n",
    "    '''\n",
    "    labels: An array that contains all the labels that correspond to the traces in 'dataset'\n",
    "    dataset: An array the contains all the traces\n",
    "    templating: Binary value that creates templates for all the labels\n",
    "    reducing: If the reduction matrix is inserted then the sorted data is reduced\n",
    "    size: An integer that must correspond to the points of interest\n",
    "    \n",
    "    Returns the best matches and potentially creates a reduced template of that match\n",
    "    '''\n",
    "    # Initialises the template matrix\n",
    "    if templating:\n",
    "        templates = np.zeros([256,size])\n",
    "        \n",
    "    sorted_sets = []\n",
    "\n",
    "    # Finds indexes of the best matches\n",
    "    for i in range(256):\n",
    "        idx = np.where(labels==i)[0]\n",
    "        data_i = dataset[idx]\n",
    "        \n",
    "        if reducing != []:\n",
    "            data_i = np.dot(data_i, reducing)\n",
    "        \n",
    "        sorted_sets.append(data_i)\n",
    "        \n",
    "        if templating:\n",
    "            templates[i] = np.mean(data_i, axis=0)\n",
    "        \n",
    "        \n",
    "    if templating:\n",
    "        return templates, sorted_sets\n",
    "    \n",
    "    return sorted_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8141879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def template_attack(templates, train_sorted, label_valtest, traces_valtest, m=1, amount=1):\n",
    "    '''\n",
    "    templates: An array that contains the templates that correspond to all labels\n",
    "    train_sorted: An array that contains the sorted traces\n",
    "    label_valtest: An array that contains all the labels for the test/validation data\n",
    "    traces_valtest: An array that contains all the traces for the test/validation data\n",
    "    \n",
    "    Returns accuracy of the template attacks\n",
    "    '''\n",
    "    # Initialise variables\n",
    "    pooled_cov = np.zeros((m,m))\n",
    "    accuracy = 0\n",
    "    attempts = 0\n",
    "\n",
    "    # Perform pca\n",
    "    Ureduces = PCA(templates, m)\n",
    "\n",
    "    # Project the data\n",
    "    templates_reduced = np.dot(templates, Ureduces)\n",
    "\n",
    "    # Compute the inverse pooled Covariance Matrix\n",
    "    for train_set in train_sorted:\n",
    "        train_reduced = np.dot(np.array(train_set), Ureduces)\n",
    "        train_set_reduced = np.dot(np.array(train_set), Ureduces)\n",
    "        pooled_cov += np.cov(train_set_reduced.T)\n",
    "    pooled_cov /= 256\n",
    "    pooled_cov_inv = np.linalg.inv(pooled_cov)\n",
    "\n",
    "    # Project the data\n",
    "    valtest_reduced = operation_sorter(label_valtest, traces_valtest, reducing=Ureduces)\n",
    "    \n",
    "    # Perform the attack\n",
    "    for operation,op in zip(valtest_reduced,range(len(valtest_reduced))):\n",
    "        for i in range(0, len(operation), amount):\n",
    "            attempts += 1\n",
    "            \n",
    "            scores = np.zeros([256,1])\n",
    "            if amount > 1:\n",
    "                attack_traces = operation[i:i+amount]\n",
    "                for attack_trace in attack_traces:\n",
    "                    for i in range(256):\n",
    "                        scores[i] += sum(-.5 * np.dot(np.dot((attack_trace - templates_reduced[i]), pooled_cov_inv), (attack_trace - templates_reduced[i]).T))\n",
    "            else:\n",
    "                attack_trace = operation[i]\n",
    "                for i in range(256):\n",
    "                    scores[i] += sum(-.5 * np.dot(np.dot((attack_trace - templates_reduced[i]), pooled_cov_inv), (attack_trace - templates_reduced[i]).T))\n",
    "\n",
    "            # If the highest score is the same as the score of the correct operation the TA is correct\n",
    "            if scores[op] == max(scores):\n",
    "                accuracy += 1\n",
    "                \n",
    "    return accuracy / attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c91271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmapmaker(templates, train_sorted, label_valtest, traces_valtest, \n",
    "                 pois = [10,20,30,40,50,60], traces_used = [1,2,4,8,16], progress=False):\n",
    "    '''\n",
    "    templates: An array that contains the templates that correspond to all labels\n",
    "    train_sorted: An array that contains the sorted traces\n",
    "    label_valtest: An array that contains all the labels for the test/validation data\n",
    "    traces_valtest: An array that contains all the traces for the test/validation data\n",
    "    pois: The number of Points Of Interests that are utilised\n",
    "    traces_used: The total number of traces that is used to make a decision\n",
    "    \n",
    "    Returns a heatmap of accuracies for every Point Of Interest with the corresponding amount of traces used.\n",
    "    '''\n",
    "    # Initiating variables\n",
    "    acc_matrix = np.zeros([len(pois),len(traces_used)])\n",
    "\n",
    "    for current_max, j in zip(traces_used, range(len(traces_used))):\n",
    "        if progress:\n",
    "            print('Current traces used: ', current_max)\n",
    "        for poi, i in zip(pois, range(len(pois))):\n",
    "            print('Pois: ', poi)\n",
    "            acc_matrix[i,j] = template_attack(templates, train_sorted, label_valtest, traces_valtest, poi, current_max)\n",
    "\n",
    "    # creating figures\n",
    "    fig = plt.figure(figsize=(10, 10)) \n",
    "    ax = fig.add_subplot(111) \n",
    "\n",
    "    # creating the heatmap\n",
    "    plt.imshow(acc_matrix) \n",
    "\n",
    "    # adding title and labels\n",
    "    ax.set_title(\"2D Heatmap of PCA TA\") \n",
    "    ax.set_xlabel('Number of traces used in decision') \n",
    "    ax.set_ylabel('Points of Interest') \n",
    "\n",
    "    # displaying plot\n",
    "    plt.show()\n",
    "    \n",
    "    return acc_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50e7081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(filename_traces, filename_labels, correlating=False, saving=True, progress=False):\n",
    "    '''\n",
    "    filename_traces: A string that corresponds to the name of a file that contains traces\n",
    "    filename_labels: A string that corresponds to the name of a file that contains labels for the traces\n",
    "    \n",
    "    Returns the correlation feature\n",
    "    '''\n",
    "    # Load traces and labels\n",
    "    traces = matloader(filename_traces, True, False)['traces']\n",
    "    labels = matloader(filename_labels, False, False)['label']\n",
    "    \n",
    "    traces_sorted = operation_sorter(labels, traces)\n",
    "    \n",
    "    # Perform a type of correlation analysis\n",
    "    if correlating:\n",
    "        correlations = np.zeros([5000,100000])\n",
    "\n",
    "        for i in range(0,256):\n",
    "            if progress and i % 5 == 0:\n",
    "                print(i)\n",
    "            temp_trace = (traces - traces.mean(axis=0))/traces.std(axis=0)\n",
    "            correlations += abs(np.dot(temp_trace.T, i)/temp_trace.shape[0])\n",
    "        if saving:\n",
    "            np.save('Correlations_abs', correlations)\n",
    "    else:\n",
    "        correlations = np.load('Correlations_abs.npy')\n",
    "        plt.plot(range(len(correlations)), np.sum(correlations, axis=1))\n",
    "        plt.show()\n",
    "    \n",
    "    return correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befd7080",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(filename_traces, filename_labels, filenames_test, filenames_labels, poi, decision_traces, \n",
    "             validating=False, progress=False, skiptest=False, iters=1, sampling=True):\n",
    "    '''\n",
    "    filename_traces: A string that corresponds to the name of a file that contains training traces\n",
    "    filename_labels: A string that corresponds to the name of a file that contains labels for the training traces\n",
    "    filenames_test: A string that corresponds to the name of a file that contains test traces\n",
    "    filenames_labels: A string that corresponds to the name of a file that contains labels for the test traces\n",
    "    poi: An integer that decides the number of Places of Interest to utilise\n",
    "    decision_traces: An integer that corresponds to the number of traces used per label to make a decision\n",
    "    validating: A logical that will immediately run heatmapmaker for testing purposes\n",
    "    progress: A logical that decides whether progress will be shown through print statements\n",
    "    skiptest: A logical that decides whether the pipeline will skip the test after training\n",
    "    iters: An integer that corresponds to how often the code will iterate\n",
    "    sampling: A logical that decides whether samples will be selected randomly from the traces\n",
    "    \n",
    "    Returns accuracies and stds from the attacks\n",
    "    '''\n",
    "    # Load the traces\n",
    "    traces = matloader(filename_traces, True, False)['traces']\n",
    "    \n",
    "    # Perform feature extraction to remove unnecessary data\n",
    "    poi_list = matloader('poi_list', False, False)['poi_list']\n",
    "    poi_list = np.concatenate(poi_list).ravel()\n",
    "    filtered_traces = traces[:, poi_list]\n",
    "    \n",
    "    if progress:\n",
    "        print('Feature extraction completed.')\n",
    "    \n",
    "    # Load the labels\n",
    "    labels = matloader(filename_labels, False, False)['label']\n",
    "    \n",
    "    # Split the data\n",
    "    train_traces = filtered_traces[0:80000]\n",
    "    train_labels = labels[0:80000]\n",
    "\n",
    "    val_traces = filtered_traces[80000:90000]\n",
    "    val_labels = labels[80000:90000]\n",
    "    \n",
    "    test_traces = filtered_traces[90000:100000]\n",
    "    test_labels = labels[90000:100000]\n",
    "    \n",
    "    if progress:\n",
    "        print('Dataset splitting completed.')\n",
    "    \n",
    "    # Create the templates and sort the data based on the labels\n",
    "    templates, train_sorted = operation_sorter(train_labels, train_traces, templating=True)\n",
    "    \n",
    "    # Initialise list to store results\n",
    "    accuracies = []\n",
    "    \n",
    "    # Get data for the parameters or get the first accuracy\n",
    "    if validating:\n",
    "        return heatmapmaker(templates, train_sorted, val_labels, val_traces, progress=True)\n",
    "    else:\n",
    "        if not skiptest:\n",
    "            print('test acc after training: ', template_attack(templates, train_sorted, test_labels, \n",
    "                                                               test_traces, poi, decision_traces))\n",
    "        \n",
    "        stds = []\n",
    "\n",
    "        for filename_test, filename_label in zip(filenames_test, filenames_labels):\n",
    "            test_traces = matloader(filename_test, True, False)['traces']\n",
    "            \n",
    "            test_traces = test_traces[:,poi_list]\n",
    "            test_labels = matloader(filename_label, False, False)['label']\n",
    "            temp_accuracies = np.zeros([iters,])\n",
    "            \n",
    "            for i in range(iters):\n",
    "                if sampling:\n",
    "                    rows = random.sample(range(100000), 10000)\n",
    "                    filtered_traces = test_traces[rows,:]\n",
    "                    filtered_labels = test_labels[rows,:]\n",
    "                else:\n",
    "                    filtered_traces = test_traces\n",
    "                    filtered_labels = test_labels\n",
    "                temp_accuracies[i] = template_attack(templates, train_sorted, filtered_labels, \n",
    "                                                     filtered_traces, poi, decision_traces)\n",
    "            \n",
    "            accuracies.append(np.mean(temp_accuracies))\n",
    "            stds.append(np.std(temp_accuracies))\n",
    "\n",
    "            if progress:\n",
    "                print(filename_test, ' completed: ', accuracies[-1], '.')\n",
    "        return accuracies, stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0885cec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def research_1(mode='validating', intermediary_vals=True, plotting=True, iterations=1):\n",
    "    '''\n",
    "    mode: A string that corresponds to the mode that is used for the run, currently only validating/other\n",
    "    intermediary_vals: A logical that decides whether intermediary values are printed\n",
    "    plotting: A logical that decides whether a plot is produced\n",
    "    iterations: Integer that corresponds to the number of iterations\n",
    "    \n",
    "    returns List of accuracies and stds, and optionally a plot\n",
    "    '''\n",
    "    # Initialse necessary variables\n",
    "    filename_traces = 'traces0'\n",
    "    filename_labels = 'label0'\n",
    "    filenames_test = ['traces1', 'traces2', 'traces3', 'traces4', 'traces5', \n",
    "                      'traces6', 'traces7', 'traces8', 'traces9', 'traces10']\n",
    "    filenames_labels = ['label1', 'label2', 'label3', 'label4', 'label5', \n",
    "                        'label6', 'label7', 'label8', 'label9', 'label10']\n",
    "    \n",
    "    if mode != 'validating':\n",
    "        mode = False\n",
    "    else:\n",
    "        return pipeline(filename_traces, filename_labels, filenames_test, filenames_labels, 50, 1, \n",
    "                          validating=mode, progress=intermediary_vals, skiptest=False, iters=iterations)\n",
    "    \n",
    "    # Run pipeline for results\n",
    "    accuracies, stds = pipeline(filename_traces, filename_labels, filenames_test, filenames_labels, 50, 1, \n",
    "                          validating=mode, progress=intermediary_vals, skiptest=False, iters=iterations)\n",
    "    if plotting:\n",
    "        fig = plt.figure()\n",
    "        plt.errorbar(range(len(accuracies)), accuracies, stds)\n",
    "        plt.show()\n",
    "    \n",
    "    return accuracies, stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3de33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def research_2(mode='validating', intermediary_vals=True, plotting=True, iterations=1):\n",
    "    '''\n",
    "    mode: A string that corresponds to the mode that is used for the run, currently only validating/other\n",
    "    intermediary_vals: A logical that decides whether intermediary values are printed\n",
    "    plotting: A logical that decides whether a plot is produced\n",
    "    iterations: Integer that corresponds to the number of iterations\n",
    "    \n",
    "    returns List of accuracies and stds, and optionally a plot\n",
    "    '''\n",
    "    # Initialse necessary variables\n",
    "    filename_traces = 'traces0'\n",
    "    filename_labels = 'label0'\n",
    "    filenames_test = ['traces15', 'traces30', 'traces45', 'traces60', 'traces75', 'traces90', \n",
    "                      'traces105', 'traces120', 'traces135', 'traces150', 'traces165', 'traces180', \n",
    "                      'traces195', 'traces210', 'traces225', 'traces240']\n",
    "    filenames_labels = ['label15', 'label30', 'label45', 'label60', 'label75', 'label90', \n",
    "                        'label105', 'label120', 'label135', 'label150', 'label165', 'label180', \n",
    "                        'label195', 'label210', 'label225', 'label240']\n",
    "        \n",
    "    if mode != 'validating':\n",
    "        mode = False\n",
    "        \n",
    "    # Run pipeline for results\n",
    "    accuracies, stds = pipeline(filename_traces, filename_labels, filenames_test, filenames_labels, 50, 1, \n",
    "                          validating=mode, progress=intermediary_vals, skiptest=False, iters=iterations)\n",
    "    if plotting:\n",
    "        fig = plt.figure()\n",
    "        plt.errorbar(range(len(accuracies)), accuracies, stds)\n",
    "        plt.show()\n",
    "    \n",
    "    return accuracies, stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333d6b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def research_3(mode='validating', intermediary_vals=True, plotting=True, iterations=1):\n",
    "    '''\n",
    "    mode: A string that corresponds to the mode that is used for the run, currently only validating/other\n",
    "    intermediary_vals: A logical that decides whether intermediary values are printed\n",
    "    plotting: A logical that decides whether a plot is produced\n",
    "    iterations: Integer that corresponds to the number of iterations\n",
    "    \n",
    "    returns List of accuracies and stds, and optionally a plot\n",
    "    '''\n",
    "    # Initialse necessary variables\n",
    "    filename_traces = 'traces0'\n",
    "    filename_labels = 'label0'\n",
    "    \n",
    "    filenames_test = ['traces243', 'traces244', 'traces245', 'traces246', 'traces247', 'traces248', 'traces249', \n",
    "                      'traces250', 'traces251', 'traces252', 'traces253', 'traces254']\n",
    "    filenames_labels = ['label243', 'label244', 'label245', 'label246', 'label247', 'label248', 'label249', \n",
    "                        'label250', 'label251', 'label252', 'label253', 'label254']\n",
    "    \n",
    "    if mode != 'validating':\n",
    "        mode = False\n",
    "    \n",
    "    # Run pipeline for results\n",
    "    accuracies, stds = pipeline(filename_traces, filename_labels, filenames_test, filenames_labels, 50, 1, \n",
    "                          validating=mode, progress=intermediary_vals, skiptest=False, iters=iterations)\n",
    "    print(accuracies, stds)\n",
    "    \n",
    "    if plotting:\n",
    "        # Create the plots\n",
    "        fig = plt.figure()\n",
    "        plt.errorbar(range(len(accuracies)), accuracies, stds, label='Not retrained')\n",
    "        plt.title('Final 10 trace files with and without retraining')\n",
    "        \n",
    "    # Initialse necessary variables\n",
    "    filename_traces = 'traces244'\n",
    "    filename_labels = 'label244'\n",
    "    \n",
    "    # Run pipeline for results\n",
    "    accuracies_retrained, stds_retrained = pipeline(filename_traces, filename_labels, filenames_test, filenames_labels, 50, 1, \n",
    "                          validating=mode, progress=intermediary_vals, skiptest=False, iters=iterations)\n",
    "    if plotting:\n",
    "        plt.errorbar(range(len(accuracies_retrained)), accuracies_retrained, stds_retrained, label='Retrained')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    return accuracies, stds, accuracies_retrained, stds_retrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cb1e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def research_4(label=0):\n",
    "    '''\n",
    "    label: Integer ranging from 0 to 255, corresponds to the labels in the dataset\n",
    "    \n",
    "    returns a plot\n",
    "    '''\n",
    "    # Load the starting labels\n",
    "    labels = matloader('label0', False, False)['label']\n",
    "    \n",
    "    # Load the starting traces\n",
    "    traces = matloader('traces0', True, False)['traces']\n",
    "    \n",
    "    # Create the templates and sort the data based on the labels\n",
    "    templates, traces = operation_sorter(labels, traces, templating=True, size=5000)\n",
    "    \n",
    "    # Create the plots\n",
    "    fig = plt.figure()\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    selected_trace = traces[label][0]\n",
    "    plt.plot(range(len(selected_trace)), selected_trace, label='trace0 single trace')\n",
    "    plt.plot(range(len(templates[label])), templates[label], label='trace0 mean trace')\n",
    "    plt.title('traces0 single trace vs traces0 mean trace')\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Power Consumption\")\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(range(len(selected_trace)), selected_trace, label='trace0 single trace')\n",
    "    \n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.plot(range(len(templates[label])), templates[label], label='trace0 mean trace')\n",
    "    \n",
    "    # Load the final labels\n",
    "    labels = matloader('label254', False, False)['label']\n",
    "    \n",
    "    # Load the final traces\n",
    "    traces = matloader('traces254', True, False)['traces']\n",
    "    \n",
    "    # Create the templates and sort the data based on the labels\n",
    "    templates, traces = operation_sorter(labels, traces, templating=True, size=5000)\n",
    "    \n",
    "    plt.subplot(2, 2, 2)\n",
    "    selected_trace = traces[label][0]\n",
    "    plt.plot(range(len(selected_trace)), selected_trace, label='trace254 single trace')\n",
    "    plt.plot(range(len(templates[label])), templates[label], label='trace254 mean trace')\n",
    "    plt.title('traces254 single trace vs traces254 mean trace')\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Power Consumption\")\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(range(len(selected_trace)), selected_trace, label='trace254 single trace')\n",
    "    plt.title('traces0 single trace vs traces254 single trace')\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Power Consumption\")\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.plot(range(len(templates[label])), templates[label], label='trace254 mean trace')\n",
    "    plt.title('traces0 mean trace vs traces254 mean trace')\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Power Consumption\")\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d649ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def research_5(mode='testing', intermediary_vals=True, plotting=True, iterations=1):\n",
    "    '''\n",
    "    mode: A string that corresponds to the mode that is used for the run, currently only validating/other\n",
    "    intermediary_vals: A logical that decides whether intermediary values are printed\n",
    "    plotting: A logical that decides whether a plot is produced\n",
    "    iterations: Integer that corresponds to the number of iterations\n",
    "    \n",
    "    returns List of accuracies and stds, and optionally a plot\n",
    "    '''\n",
    "    # Initialse necessary variables\n",
    "    filename_traces = 'traces0'\n",
    "    filename_labels = 'label0'\n",
    "    filenames_test = ['traces1', 'traces2', 'traces3', 'traces4', 'traces5', 'traces6', \n",
    "                      'traces7', 'traces8', 'traces9', 'traces10', 'traces15', 'traces30', \n",
    "                      'traces45', 'traces60', 'traces75', 'traces90', 'traces105', 'traces120', \n",
    "                      'traces135', 'traces150', 'traces165', 'traces180', 'traces195', 'traces210', \n",
    "                      'traces225', 'traces240', 'traces244', 'traces245', 'traces246', 'traces247', \n",
    "                      'traces248', 'traces249','traces250', 'traces251', 'traces252', 'traces253', 'traces254']\n",
    "    \n",
    "    filenames_labels = ['label1', 'label2', 'label3', 'label4', 'label5', 'label6', \n",
    "                        'label7', 'label8', 'label9', 'label10', 'label15', 'label30', \n",
    "                        'label45', 'label60', 'label75', 'label90', 'label105', 'label120', \n",
    "                        'label135', 'label150', 'label165', 'label180', 'label195', 'label210', \n",
    "                        'label225', 'label240', 'label244', 'label245', 'label246', 'label247', \n",
    "                        'label248', 'label249', 'label250', 'label251', 'label252', 'label253', 'label254']\n",
    "        \n",
    "    if mode != 'validating':\n",
    "        mode = False\n",
    "        \n",
    "    # Run pipeline for results\n",
    "    accuracies, stds = pipeline(filename_traces, filename_labels, filenames_test, filenames_labels, 50, 1, \n",
    "                          validating=mode, progress=intermediary_vals, skiptest=False, iters=iterations, sampling=False)\n",
    "    if plotting:\n",
    "        fig = plt.figure()\n",
    "        plt.errorbar(range(len(accuracies)), accuracies, stds)\n",
    "        plt.show()\n",
    "    \n",
    "    return accuracies, stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bc586a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "accuracies_matrix = research_1(mode='validating', intermediary_vals=True, plotting=True, iterations=50)\n",
    "t1 = time.time()\n",
    "\n",
    "print('Time taken: ', t1-t0)\n",
    "\n",
    "# Saves results after run\n",
    "# np.save('acc_1', accuracies_1)\n",
    "# np.save('stds_1', stds_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691f89d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_matrix\n",
    "\n",
    "# creating figures\n",
    "fig = plt.figure(figsize=(10, 10)) \n",
    "ax = fig.add_subplot(111) \n",
    "\n",
    "# creating the heatmap\n",
    "plt.imshow(accuracies_matrix)\n",
    "\n",
    "x = np.array([1,2,4,8,16]) # the grid to which your data corresponds\n",
    "nx = x.shape[0]\n",
    "no_labels = 5 # how many labels to see on axis x\n",
    "step_x = int(nx / (no_labels - 1)) # step between consecutive labels\n",
    "x_positions = np.arange(0,nx,step_x) # pixel count at label position\n",
    "x_labels = x[::step_x] # labels you want to see\n",
    "plt.xticks(x_positions, x_labels)\n",
    "\n",
    "y = np.array([10,20,30,40,50,60]) # the grid to which your data corresponds\n",
    "ny = y.shape[0]\n",
    "no_labels = 6 # how many labels to see on axis x\n",
    "step_y = int(ny / (no_labels - 1)) # step between consecutive labels\n",
    "y_positions = np.arange(0,ny,step_y) # pixel count at label position\n",
    "y_labels = y[::step_y] # labels you want to see\n",
    "plt.yticks(y_positions, y_labels)\n",
    "\n",
    "# ax.set_aspect(2)\n",
    "\n",
    "# adding title and labels\n",
    "ax.set_title(\"2D Heatmap of PCA TA\") \n",
    "ax.set_xlabel('Number of traces used in decision') \n",
    "ax.set_ylabel('Points of Interest') \n",
    "\n",
    "# displaying plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2eeeb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "accuracies_2, stds_2 = research_2(mode='testing', intermediary_vals=True, plotting=True, iterations=50)\n",
    "t1 = time.time()\n",
    "\n",
    "print('Time taken: ', t1-t0)\n",
    "\n",
    "# Saves results after run\n",
    "# np.save('acc_2', accuracies_2)\n",
    "# np.save('stds_2', stds_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ececa662",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "accuracies_3, stds_3, accuracies_3_retrained, stds_3_retrained = research_3(mode='testing', intermediary_vals=True, \n",
    "                                                                            plotting=True, iterations=50)\n",
    "t1 = time.time()\n",
    "\n",
    "print('Time taken: ', t1-t0)\n",
    "\n",
    "# Saves results after run\n",
    "# np.save('acc_3', accuracies_3)\n",
    "# np.save('stds_3', stds_3)\n",
    "# np.save('acc_retrained_3', accuracies_retrained_3)\n",
    "# np.save('stds_3_retrained', stds_retrained_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf5e23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_3_retrained = np.load('acc_retrained_3.npy')\n",
    "accuracies_3_retrained = np.insert(accuracies_3_retrained,0,0.5472,axis=0)\n",
    "\n",
    "accuracies_3 = np.load('acc_3.npy')\n",
    "\n",
    "stds_3 = np.load('stds_3.npy')\n",
    "\n",
    "\n",
    "print(len(accuracies_3))\n",
    "print(accuracies_3)\n",
    "print(len(stds_3))\n",
    "\n",
    "stds_3_retrained = np.load('stds_3_retrained.npy')\n",
    "stds_3_retrained = np.insert(stds_3_retrained,0,0,axis=0)\n",
    "xax = range(244,255)\n",
    "\n",
    "print(len([i for i in xax]))\n",
    "\n",
    "(_, caps, _) = plt.errorbar(\n",
    "    xax, accuracies_3, yerr=stds_3, capsize=2, label='Without Retraining')\n",
    "\n",
    "(_, caps, _) = plt.errorbar(\n",
    "    xax, accuracies_3_retrained, yerr=stds_3_retrained, capsize=2, label='With Retraining')\n",
    "\n",
    "for cap in caps:\n",
    "    cap.set_markeredgewidth(1)\n",
    "\n",
    "plt.title('TA accuracy over time')\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79428da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for vals in range(0, 255, 15):\n",
    "    t0 = time.time()\n",
    "    research_4(label=vals)\n",
    "    t1 = time.time()\n",
    "\n",
    "    print('Time taken', vals, ': ', t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb010fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "acc_5, stds_5 = research_5()\n",
    "t1 = time.time()\n",
    "\n",
    "print('Time taken: ', t1-t0)\n",
    "\n",
    "# Saves results after run\n",
    "# np.save('acc_5', acc_5)\n",
    "# np.save('stds_5', stds_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecceec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays a single trace\n",
    "\n",
    "# trace = matloader('traces0', True, False)['traces'][0]\n",
    "# fig = plt.figure()\n",
    "# plt.plot(range(len(trace)), trace)\n",
    "# plt.title('Power Trace')\n",
    "# plt.xlabel(\"Time\")\n",
    "# plt.ylabel(\"Power Consumption\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
